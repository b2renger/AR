<!doctype html>
<html>

<head>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <script src="https://aframe.io/releases/1.7.1/aframe.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.5/dist/mindar-image-aframe.prod.js"></script>

  <script defer>
    // https://github.com/nikolaiwarner/aframe-chromakey-material
    // think about : https://github.com/b2renger/p5js-shaders/tree/master/AF-shader-vertex-displacement
    AFRAME.registerShader('chromakey', {
      schema: {
        src: { type: 'map' },
        color: { default: { x: 0.0, y: 1.0, z: 0.0 }, type: 'vec3', is: 'uniform' },
        chroma: { type: 'bool', is: 'uniform' },
        transparent: { default: true, is: 'uniform' },
        // New properties for displacement
        displacement: { type: 'bool', default: false, is: 'uniform' },
        damplitude: { type: 'float', default: 0.0, is: 'uniform' }
      },

      init: function (data) {

        var videoTexture = new THREE.VideoTexture(data.src)
        videoTexture.minFilter = THREE.LinearFilter
        this.material = new THREE.ShaderMaterial({
          uniforms: {
            chroma: {
              type: 'b',
              value: data.chroma
            },
            color: {
              type: 'c',
              value: data.color
            },
            myTexture: {
              type: 't',
              value: videoTexture
            },
            // New uniforms for displacement
            displacement: {
              type: 'b',
              value: data.displacement
            },
            damplitude: {
              type: 'f',
              value: data.damplitude
            },
             // A-Frame provides time uniform automatically
          },
          vertexShader:
            `
            #ifdef GL_ES
            precision mediump float;
            #endif

            // A-Frame provides these built-in attributes and uniforms automatically
            // attribute vec3 position;
            // attribute vec2 uv;
            // attribute vec3 normal;
            // uniform mat4 modelViewMatrix;
            // uniform mat4 projectionMatrix;
            uniform float time; // A-Frame time uniform (milliseconds)

            // Existing uniform for video texture
            uniform sampler2D myTexture;

            // New uniforms
            uniform bool displacement;
            uniform float damplitude;

            // Varying to pass texture coordinates to the fragment shader
            varying vec2 vUv;

            void main(void) {
              vUv = uv; // Pass the original texture coordinates

              vec3 displacedPosition = position; // Start with original position

              if (displacement) {
                // Sample the video texture using UV coordinates for displacement
                // Use a different UV for sampling the video texture if needed, 
                // but for now, using the geometry's UV for displacement texture lookup
                vec4 noise = texture2D(myTexture, fract(uv));

                // Calculate a single float noise value from the RGB channels, centered around 0
                float noiseValue = dot(noise.rgb, vec3(0.333)) - 0.5; // Value between -0.5 and 0.5

                // Calculate displacement strength based on time and amplitude uniform
                // Scale time to seconds
                float displacementStrength =  damplitude;

                // Apply displacement only along the Y axis as per the user's provided shader logic
                displacedPosition.z += noiseValue * displacementStrength;
              }

              // Calculate final position in clip space using the displaced position
              vec4 mvPosition = modelViewMatrix * vec4(displacedPosition, 1.0);
              gl_Position = projectionMatrix * mvPosition;
            }
          `
          ,
          fragmentShader:
            `
            #ifdef GL_ES
            precision mediump float;
            #endif

            uniform sampler2D myTexture; // The video texture
            uniform vec3 color;         // Chromakey color
            uniform bool chroma;        // Chromakey enabled flag

            varying vec2 vUv;           // Texture coordinates from the vertex shader

            void main(void) {
              vec3 tColor = texture2D(myTexture, vUv).rgb; // Sample the video texture
              float a; // Alpha value

              if (chroma) {
                // Chromakey calculation
                a = (length(tColor - color) - 0.5) * 7.0;
              } else {
                a = 1.0;
              }

              // Clamp alpha between 0.0 and 1.0
              a = clamp(a, 0.0, 1.0);

              // Output the color with the calculated alpha
              gl_FragColor = vec4(tColor, a);
            }
            `
        })
      },

      update: function (data) {
        this.material.color = data.color;
        this.material.src = data.src;
        this.material.transparent = data.transparent;
        // Update new uniforms
        this.material.uniforms.displacement.value = data.displacement;
        this.material.uniforms.damplitude.value = data.damplitude;
        // No need to update noiseTexture uniform as we are using myTexture
      },

    })

  </script>


  <script defer>
    AFRAME.registerComponent('play-on-click', {
      init: function () {
        this.onClick = this.onClick.bind(this);

        this.el.addEventListener('targetFound', event => {
          console.log("target found");
          var videoEl = this.el.getAttribute('material').src;
          if (!videoEl) { return; }
          this.el.object3D.visible = true;
          // Check if video is already playing before attempting to play
          if (videoEl.paused) {
             videoEl.play();
          }

        });
        this.el.addEventListener('targetLost', event => {
          console.log("target lost"); // Corrected console log
          var videoEl = this.el.getAttribute('material').src;
          if (!videoEl) { return; }
          this.el.object3D.visible = false;
          // Pause only if video is playing
          if (!videoEl.paused) {
             videoEl.pause();
          }
        });
      },
      play: function () {
        window.addEventListener('click', this.onClick);
      },
      pause: function () {
        window.removeEventListener('click', this.onClick);
      },
      onClick: function (evt) {
        var videoEl = this.el.getAttribute('material').src;
        if (!videoEl) { return; }
        this.el.object3D.visible = true;
         if (videoEl.paused) {
             videoEl.play();
          }
      }
    });
  </script>

</head>

<body style="margin : 0px; overflow: hidden;">

  <a-scene mindar-image="imageTargetSrc:assets/test_target.mind;" color-space="sRGB"
    renderer="colorManagement: true, physicallyCorrectLights" vr-mode-ui="enabled: false"
    device-orientation-permission-ui="enabled: false">

    <a-assets>
      <video src="./assets/Test.mp4#t=0.1" muted="true" loop="true" controls="false" playsinline webkit-playsinline
        type='video/mp4' id="vid"></video>
      <!-- Removed the noise texture image -->
    </a-assets>

    <a-entity mindar-image-target="targetIndex: 0" play-on-click
      material="shader: chromakey; src: #vid; chroma: false; color: 0. 0. 1.; displacement: true; damplitude: -1.5"
      geometry="primitive: plane; width:  1; height:  1.6; segments-width: 100; segments-height: 100"
      position="0  0  0" rotation="270  0  0" side="double">
    </a-entity>

    <a-camera position="0 0 0" look-controls="enabled: false"></a-camera>

  </a-scene>

</body>

</html>